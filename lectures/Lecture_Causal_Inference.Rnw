% Copyright (C) 2015 Jeffrey B. Arnold
% License CC BY-NC-SA 4.0 http://creativecommons.org/licenses/by-nc-sa/4.0/

<<init,echo=FALSE,results='hide',warning=FALSE,message=FALSE>>=
source("init.R")
@
<<header>>=
suppressPackageStartupMessages({
  library("car")
  library("gapminder")
})
@

\input{\jobname-options}
\ifdefined\ishandout%
  \documentclass[handout]{beamer}
\else
  \documentclass[]{beamer}
\fi

%%%INSERTHEADERHERE

\input{includes.tex}

\DeclareMathOperator{\CEF}{CEF}

\newcommand{\thetitle}{Causal Inference}
\date{May 26, 2015}
\title{\thetitle{}}
\hypersetup{
  pdftitle={\thetitle{}},
  pdfkeywords={statistics}
}

\def\ci{\perp\!\!\!\perp}

\begin{document}


\begin{frame}
  \maketitle{}
\end{frame}


\begin{frame}
\frametitle{Overview}
\tableofcontents
\end{frame}



\section{Causal Inference and Potential Outcomes}


\begin{frame}
  \frametitle{Prediction vs. Causal Inference}

  Consider a relationship between $X$ and $Y$:

  \begin{block}{Prediction}
    \begin{itemize}
    \item Given values of $x$ predict $y$.
    \item Compare values of $y$ for different values of $x$
    \item This is a comparison \textbf{between} individuals
    \end{itemize}

  \end{block}

  \begin{block}{Causal Inference}
    \begin{itemize}
    \item Comparison \textbf{within} individuals
    \item For the \textbf{same individual}, what \textit{would happen} as a result of a hypothesized ``treatment'' value of $x$
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Causal vs. Casual Inference}

  \begin{itemize}
  \item Non causal inference
  \item A typo
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{What is the effect of hospitals on health?}

  \begin{itemize}[<+->]
  \item Should we compare the health of those in hospitals with those outside hospitals?
  \item Counterfactual: For individuals, what would have happened if they went to a hospital, or not?
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{What is the effect of hospitals on health?}

  The causal effect of going to the hospital is, for two individuals:
  \begin{itemize}
  \item (health of Annie if she goes hospital) - (health if she does not)
  \item (health of Jeff if he goes to the hospital) - (health if he does not)
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Potential Outcome Framework}

  Consider a  \textbf{treatment} variable $D_{i} = \{0, 1\}$?

  \begin{equation*}
    \text{Potential outcome} =
    \begin{cases}
      Y_{i}(1) & \text{if $D_{i} = 1$} \\
      Y_{i}(0) & \text{if $D_{i} = 0$} \\
    \end{cases}
  \end{equation*}

  The treatment variable can be continuous or ordinal, but easier to reason about the binary case for now.
  
\end{frame}


\begin{frame}
  \begin{center}
  \begin{tabular}{lccc}
    & No Hospital & Hospital & Casual Effect \\
    Person & $Y_{i}(0)$ & $Y_{i}(1)$ & $Y_{i}(0) - Y_{i}(1)$  \\
    \hline    
    Annie & 8  & 10 & 2 \\
    Jeff &  5 &  10 & 5\\
    Abed & 1 & 7 & 6 \\
    Britta & 5 & 10 & 5 \\
    Chang & 3 & 5 & 2 \\
    Frankie & 6 & 8 & 2 \\
    \hline                      
  \end{tabular}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{The fundamental problem of causal inference}

  \begin{center}
    We only observe one potential outcome --- the observation; we cannot observe both $Y_{i}(1)$ and $Y_{i}(0)$.
  \end{center}

\end{frame}


\begin{frame}
  \begin{center}
  \begin{tabular}{lccc}
    & No Hospital & Hospital & Treatment \\
    Person & $Y_{i}(0)$ & $Y_{i}(1)$ & $D_{i}$  \\
    \hline
    Annie & 8  &  & 0\\
    Jeff &  5 &   & 0\\
    Abed & 1 &  & 0 \\
    Britta &  & 10 & 1 \\
    Chang &  & 5 & 1 \\
    Frankie &  & 8 & 1 \\
    \hline                      
  \end{tabular}
  \end{center}
  
  We can only observe one outcome for any individual.
  
\end{frame}


\begin{frame}
  \frametitle{How does the potential outcome relate to observed outcome?}

  \begin{itemize}
  \item Need a way to connect potential outcomes to observed outcomes.
  \item \textbf{SUTVA}: Stable unit treatment value assumption
  \item Also called a ``consistency'' assumption
  \item What is SUTVA?
  \item The outcome observed for a value of a treatment is equal to the potential outcome for that treatment value.
    \begin{equation*}
      Y_{i} \text{ if $D_{i} = d$} = Y_{i}(d) \text{ for $d \in \{0, 1\}$}
    \end{equation*}
  \item No interference between units. Potential outcomes of units is unaffected by the treatments received by other units.
  \item Not all ``treatments'' can be used, there may ill-defined counterfactuals. 
  \item If there is interference, you need to think about the problem and redefine treatment or units
  \end{itemize}
\end{frame}


\begin{frame}
  
  \begin{center}
  \begin{tabular}{lcccc}
    & No Hospital & Hospital & Treatment & Observed Outcome \\
    Person & $Y_{i}(0)$ & $Y_{i}(1)$ & $D_{i}$ & $Y_i$ \\
    \hline
    Annie & 8  &  & 0 & 8 \\
    Jeff &  5 &   & 0 & 5\\
    Abed & 1 &  & 0  & 1\\
    Britta &  & 10 & 1 & 10\\
    Chang &  & 5 & 1 & 5\\
    Frankie &  & 8 & 1 & 8\\
    \hline                      
  \end{tabular}
  \end{center}

  \begin{itemize}
  \item If SUTVA, the observed outcome has to match the potential outcome for that treatment
  \item Example of failure: health of Chang depends on whether Jeff goes to the hospital.
  \end{itemize}
  
\end{frame}



\subsection{Estimands}



\begin{frame}
  \frametitle{What causal effects are there?}

  Suppose population of units $i = 1, \dots, N$

  \begin{description}
  \item [Individual Causal Effect (ICE)]
    \begin{equation*}
      \tau_{i} = Y_{i}(1) - Y_{i}(0)
    \end{equation*}
  \item [Average Treatment Effect (ATE)] The average causal effect
    \begin{equation*}
      \tau = \E(\tau_{i}) = \frac{1}{N} \sum_{i:X_{i} = x} Y_{i}(1) - Y_{i}(0)
    \end{equation*}
  \end{description}


\end{frame}

\begin{frame}
  \frametitle{Causal effects for subpopulations}

  \begin{description}
  \item [Conditional Average Treatment effect (CATE)] ATE for a subpopulation
    \begin{equation*}
      \tau(x) = \E(\tau_{i} | X = x) = \frac{1}{N_{x}} \sum_{i: X_{i} = x} (Y_{i}(1) - Y_{i}(0))
    \end{equation*}
  \item [Average treatment effect on the treated (ATT)] Causal effect for those that were treated.
    \begin{equation*}
      \tau_{ATT} = \E(\tau_{i} | D_{i} = 1) = \frac{1}{\sum D_{i}} \sum_{i: D_{i} = 1} (Y_{i}(1) - Y_{i}(0))
    \end{equation*}
  \end{description}

\end{frame}

\begin{frame}
  \begin{tabular}{lcccc}
    & No Hospital & Hospital & ICE & Treatment  \\
    Person & $Y_{i}(0)$ & $Y_{i}(1)$ & $Y_{i}(0) - Y_{i}(1)$ & $D_{i}$  \\
    \hline    
    Annie & 8  & 10 & 2 & 0\\
    Jeff &  5 &  10 & 5 & 0 \\
    Abed & 1 & 7 & 6 & 0 \\
    Britta & 5 & 10 & 5 & 1 \\
    Chang & 3 & 5 & 2 & 1 \\
    Frankie & 6 & 8 & 2 & 1 \\
    \hline                      
  \end{tabular}

  \begin{align*}
    \text{ATE} = (2 + 5 + 6 + 5 + 2 + 2) / 6 \approx 3.7 \\
    \text{CATE(men)} = (5 + 6 + 2) / 3 \approx 4.3 \\
    \text{ATT} = (5 + 2 + 2) / 3 = 3 \\    
  \end{align*}
  
\end{frame}


\begin{frame}
  \frametitle{Why use different estimands?}
  
  
\end{frame}

\begin{frame}
  \frametitle{Identification}
  \begin{itemize}
  \item If you had infinite data (entire population, no sampling variation) could you estimate the parameter uniquely?
  \item E.g.\@example of non-identification in regression is collinearity
  \item \textbf{Non parametric identification} Don't require a parametric model of data.
  \item \textbf{Parametric identification} Estimand identified assuming a parametric model of the data,
    not identified otherwise
  \item Causal inference concerned with the identification of causal estimands like ATE, ATT.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{What's the key to causal inference?}

  \begin{center}
    Data + assumptions = causal inference
  \end{center}

  ``What's your identification strategy?'' means ``What assumptions are required to estimate a causal effect?''

\end{frame}

\begin{frame}
  \frametitle{The Selection Problem}

  We cam rewrite the observed outcome as:
  \begin{align*}
      Y_{i} & =
      \begin{cases}
        Y_{i}(1) & \text{if $D_{i} = 1$} \\
        Y_{i}(0) & \text{if $D_{i} = 0$}
      \end{cases} \\
            &= Y_{i}(1) D_{i} + 1 - Y_{i}(0) (1 - D_{i}) \\
            & = Y_{i}(0) + (Y_{i}(1) - Y_{i}(0)) D_{i} \\
            & = \text{(potential outcome for non-treatment)} \\
            & \qquad + \text{(causal effect of treatment if treated)}
  \end{align*}
  
  The observe value of the individual is the sum of their outcome if not treated
  and the causal effect of the treatment.

\end{frame}


\begin{frame}
  \frametitle{Avg. Causal Effects and the Selection Bias}

  Observation and causal effects:
  \begin{align*}
    &\E(Y_{i}|D_{i} = 1) - \E(Y_{i} | D_{i} = 0)  && \text{Obs.\@difference in means} \\
    &\quad = \E(Y_{i}(1) | D_{i} = 1) - \E(Y_{i}(1) | D_{i} = 1) && \text{ATT} \\
    &\quad + \E(Y_{i}(0)|D_{i} = 1) - \E(Y_{i}(0) | D_{i} = 0) && \text{Selection bias}
  \end{align*}
  
  \begin{itemize}
  \item Selection bias: how diferent treated and untreated groups are under control (when $D_i = 0$)
  \item Because of the selection bias, ATT is unidentified. E.g.\@If ATT negative, could chose a large enough 
    selection effect to make the difference in means positive.
  \end{itemize}

\end{frame}


\section{Experiments and Causal Inference}


\begin{frame}
  \frametitle{How randomization solves the selection Problem}

  If $D_{i}$ is randomly assigned then 

  \begin{align*}
    &\E(Y_{i} | D_{i} = 1) - \E(Y_{i} | D_{i} = 0) && \text{Difference in means} \\
    &\quad  = \E(Y_{i}(1) | D_{i} = 1) - \E(Y_{i}(0) | D_{i} = 0) && \text{SUTVA} \\
    &\quad  = \E(Y_{i}(1) | D_{i} = 1) - \E(Y_{i}(0) | D_{i} = 1) && (Y_{i}(0), Y_{i}(1)) \ci D_{i} \\
    &\quad  = \E(Y_{i}(1) - Y_{i}(0) | D_{i} = 1) && \text{Diff means is mean of diffs} \\
    &\quad  = \E(Y_{i}(1) - Y_{i}(0)) && \text{$D_{i}$ is indep of potential outcomes}
  \end{align*}

\end{frame}


\begin{frame}
  \frametitle{How randomization solves the selection problem}

  \begin{itemize}
  \item Since $D_{i}$ is indep of potential outcomes, can measure average causal effect using
    a simple difference in means
  \item Randomization makes the treated and untreated groups equal on average, e.g. on average
    $E(X_{i} | D_{i} = 1) = E(X_{i} | D_{i} = 0)$ for any known or unknown $X_{i}$
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Linear Constant Effects, Binary Treatment}

  Consider an experiment with a single binary treatment
  \begin{align*}
    Y_{i} &=  Y_{i}(0) + (Y_{i}(1) - Y_{i}(0)) D_{i} \\
          &= \alpha + \tau D_{i} + (Y_{i}(0) - \alpha) \\
          &= \alpha + \tau D_{i} + \eta
  \end{align*}

  Compare
  \begin{align*}
    E(Y_{i} | D_{i} = 1) &= \alpha + \tau + E(\eta_{i} | D_{i}  = 1) \\
    E(Y_{i} | D_{i} = 0) &= \alpha + E(\eta_{i} | D_{i} = 0) \\
  \end{align*}

  Difference is ATE + selection, but selection effect is 0
  \begin{align*}
    E(Y_{i} | D_{i} = 1) - E(Y_{i} | D_{i} = 0) &= \tau + E(\eta_{i} | D_{i} = 1) - E(\eta_{i} | D_{i} = 0) \\
    &= 0
  \end{align*}

\end{frame}



\section{Observational Studies, Regression}


\begin{frame}
  \frametitle{Selection on observables}

  Conditional on observed covariates $X_{i}$, selection bias disappears
  \begin{equation*}
    \{Y_{i}(1), Y_{i}(0) \} \ci D_{i} | X_{i}
  \end{equation*}
  Means
  \begin{equation*}
    E(Y_{i} | X_{i}, D_{i} = 1) - E(Y_{i} | X_{i}, D_{i} = 0) = E(Y_{i}(1) - Y_{i}(0) | X_{i})
  \end{equation*}

  \begin{itemize}
  \item Given $X_{i}$, assignment of $D_{i}$ is ``as if'' random
  \item This assumption allows for a causal interpretation of observational studies
  \item Also called \textbf{conditional independence assumption}, \textbf{ignorability},
    \textbf{no omitted variables}, \textbf{no unmeasured confounders}

  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Estimating Causal Effects Given Observational Data}

  Using the selection on observables assumption several methods to estimate causal effects:
  \begin{itemize}
  \item Regression
  \item Matching
  \item Propensity
  \item Weighting
  \end{itemize}

  Other methods: instrumental variables, panels, difference in difference, regression discontinuity

\end{frame}


\begin{frame}
  \frametitle{Regression and Causality}

  \begin{itemize}
  \item Regression is causal when the CEF it approximates is causal (Angrist and Pischke 2008)
    \begin{itemize}
    \item Selection-on-observables assumption is correct
    \end{itemize}
  \item recovers a causal parameter, not necessarily the one we want.always
    \begin{itemize}
    \item When individual causal effects are linear and homogeneous: ATE
    \item When individual causal effects are non-linear or heterogeneous:
      \begin{itemize}
      \item weighted average treatement effect
      \item weights are the variance of the treatment conditional on the value of $X_{i}$,
        with binary $D$, highest where $\Pr(D_i = 1 | X_i) = 0.5$.
      \end{itemize}
    \end{itemize}
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Regression and the CEF}

  Conditional expectation function (CEF)
  \begin{equation*}
    \text{CEF} = \E(Y | X)
  \end{equation*}
  Linear regression
  \begin{equation}
    Y_{i} = X_{i} \beta + \epsilon_{i} \approx \E(Y_{i} | X_{i}) + \epsilon_{i}
  \end{equation}

  \begin{itemize}
  \item Linear regression estimates the CEF, when the CEF is linear.
  \item When is the CEF likely linear
    \begin{itemize}
    \item $X$ is multivariate normal
    \item $X$ is saturated, e.g.\@all combinations of binary $X$
    \end{itemize}
  \item $X'_{i} \beta$ is minimum MSE predictor of $Y_{i}$.
  \item $X'_{i} \beta$ is minimum MSE predictor of the CEF, $E(Y_{i}|X_{i})$.
  \item \textbf{Agnostic view of regression}. Linear approximation of the CEF, not ``true model''.
    Heteroskedasticity will occur use robust standard errors.
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Saturated Regression}

  Suppose $X_{1}$, and $X_{2}$ are binary variables, the saturated regression is
  \begin{equation*}
    Y_{i} = \alpha + \beta_{1} X_{1i} + \beta_{2} X_{2i} + \beta_{3} X_{1i} X_{2i} + \epsilon_{i}
  \end{equation*}
  which implies
  \begin{align*}
    \E(Y_{i} | X_{1i} = 0, X_{2i} = 0) & = \alpha \\
    \E(Y_{i} | X_{1i} = 0, X_{2i} = 1) & = \alpha + \beta_{2} \\
    \E(Y_{i} | X_{1i} = 1, X_{2i} = 0) & = \alpha + \beta_{1} \\
    \E(Y_{i} | X_{1i} = 1, X_{2i} = 1) & = \alpha + \beta_{1} + \beta_{2} + \beta_{3}
  \end{align*}

  \begin{itemize}
  \item There is a parameter for each unique combination of the covariates
  \item Linear regression \textbf{always} fits the CEF because the CEF is a linear combination of the categories. No assumptions about the CEF.
  \item Most flexible linear regression model; Dropping interaction terms, making linearity assumptions on multi-category variables cause the regression model to be no longer saturated.
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Linear Regression, constant effects, binary treatment}

  \begin{itemize}
  \item
  Assume a linear model for the potential outcomes
  \begin{equation*}
    Y_{i} &= \alpha + \tau D_{i} + \eta_{i}
  \end{equation*}
   \item The error term $\eta_{i}$ is mean 0, and captures the other effects of
     where $\E(\eta_{i}) = 0$.
   \item Suppose $\E(Y_{i}(1) - Y_{i}(0))$ is the same for everyone, and linear (true because $D_{i}$ is binary).
  \end{itemize}


\end{frame}


\begin{frame}
  \frametitle{Linear Regression, constant effects, binary treatment}

  \begin{itemize}
  \item Assume $\eta_{i} = X_{i}' \beta + \epsilon_{i}$ and $E(\eta_{i}) = X_{i}' \beta$
    \begin{align*}
      \E(Y_{i} | D_{i}, X_{i}) = E(Y_{i}(d) | X_{i}) &= \alpha + \tau D_{i} + \E(\eta_{i} | X_{i}) \\
      &= \alpha + \tau D_{i} + X'_{i} \beta + \E(\epsilon_{i} | X_{i}) \\
      &= \alpha + \tau D_{i} + X'_{i} \beta
    \end{align*}
  \item Suppose selection-on-observables holds
  \begin{equation*}
    (Y_{i}(0), Y_{i}(1)) \ci D_{i} | X_{i}
  \end{equation*}

  \end{itemize}

\end{frame}



\begin{frame}
  \frametitle{Heterogeneous or nonlinear effects}

  \begin{itemize}
  \item Suppose individual causal effects are not equal, or not-linear.
  \item Regression estimates a single parameter $\tau_{R}$:
    \begin{equation*}
      Y_{i} = \tau_{R} D_{i} + \beta X_{i} + \epsilon_{i}
    \end{equation*}
  \item Is $\tau_{R}$ equal to ATE or ATT?
  \item No. $\tau_{R}$ is a weighted ATE, weighted by the variance of $D | X$,
    and with most weight to highest variance. With binary $D$, this is $\Pr(D_{i} = 1 | X_{i}) = 0.5$.
  \item Matching methods can give the ATT
  \item See \textit{Mostly Harmless}, Ch 3.3.
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Why Regression for Causal Effects?}

  \begin{itemize}
  \item CEF approximation results
  \item If causal CEF is linear: gives ATE
  \item If causal CEF is heterogeneous or non-linear: weighted average of ICE
  \item In all cases can interpret regression coefficient directly
  \item In other words simple and usually gives you something close to what you want
  \end{itemize}

\end{frame}


\begin{frame}
  \frametitle{Important Considerations when Using Regression for Causal Questions}

  \begin{itemize}
  \item Define a ``treatment variable'' and ``control variables''
  \item Consider only one ``treatment variable'':
    \begin{itemize}
    \item It is difficult to reasonably ensure selection on observables for different variables.
    \item Study the effects of one cause, not $H_{1}, \dots, H_{\infty}$
    \item Defining the causes of an effect is either hard or ill-defined
    \item Always ask yourself, what would be the ideal randomized experiment?
    \end{itemize}
  \end{itemize}

\end{frame}


\section{etc}


\begin{frame}
  \frametitle{Comments on ``Credibility Revolution''}

  \begin{itemize}
  \item Less concern about finding the \textbf{true model}
  \item More concern about removing OVB using design
  \item Focus on estimating average causal effects
  \end{itemize}

\end{frame}



\section{References}


\begin{frame}
  \frametitle{References}

  \begin{itemize}
  \item Many slides derived from: Matthew Blackwell, GOV 2002 Notes \url{http://www.mattblackwell.org/files/teaching/gov2002-syllabus.pdf.
  \item Many derivations of equations from Angrist and Pischke, \textit{Mostly Harmless Econometrics: An Empiricist's Companion}, Ch 2--3
  \item Angrist and Pischke, \textit{Mastering Metrics: The Path from Cause to Effect}, Ch 1--2
  \item Gelman and Hill, Chapter 9 and 10
  \item Matthew Blackwell, PSC 504 Notes, \url{http://www.mattblackwell.org/teaching/psc504/}.
  \item Gelman and Hill, Ch 5. This should have most material you need.
  \end{itemize}
\end{frame}

\end{document}

%%  LocalWords:  SUTVA counterfactuals Estimands ATT Estimand 0i Diff
%%  LocalWords:  estimands diffs indep ignorability confounders CEF
%%  LocalWords:  MSE Heteroskedasticity OLS 1i 2i Angrist Pischke OVB
%%  LocalWords:  Gelman PSC
