% Copyright (C) 2015 Jeffrey B. Arnold
% License CC BY-NC-SA 4.0 http://creativecommons.org/licenses/by-nc-sa/4.0/

<<init,echo=FALSE,results='hide',warning=FALSE,message=FALSE>>=
source("init.R")
@
<<header>>=
suppressPackageStartupMessages({
  library("car")
  library("gapminder")
})
@

\input{\jobname-options}
\ifdefined\ishandout%
  \documentclass[handout]{beamer}
\else
  \documentclass[]{beamer}
\fi

%%%INSERTHEADERHERE

\input{includes.tex}

\usepackage{verbatim}

\newcommand{\thetitle}{Casual Inference}
\date{May 23, 2015}
\title{\thetitle{}}
\hypersetup{
  pdftitle={\thetitle{}},
  pdfkeywords={statistics}
}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}


\def\ci{\perp\!\!\!\perp}

\begin{document}


\begin{frame}
  \maketitle{}
\end{frame}


\begin{frame}
\frametitle{Overview}
\tableofcontents
\end{frame}



\section{Causal Inference and Potential Outcomes}


\begin{frame}
  \frametitle{Prediction vs. Casual Inference}
  
  Consider a relationship between $X$ and $Y$:
  
  \begin{block}{Prediction}
    \begin{itemize}
    \item Given values of $x$ predict $y$.
    \item Compare values of $y$ for different values of $x$
    \item This is a comparison \textbf{between} individuals
    \end{itemize}
    
  \end{block}

  \begin{block}{Causal Inference}
    \begin{itemize}
    \item Comparison \textbf{within} individuals
    \item For the \textbf{same individual}, what \textit{would happen} as a result of a hypothesized ``treatment'' value of $x$
    \end{itemize}
  \end{block}
  
\end{frame}


\begin{frame}
  \frametitle{Potential Outcome Framework}
  
  What is the effect of binary \textbf{treatment} variable $D_{i} = \{0, 1\}$? 
  
  \begin{equation*}
    \text{Potential outcome} = 
    \begin{cases}
      Y_{i}(1) & \text{if $D_{i} = 1$} \\
      Y_{i}(0) & \text{if $D_{i} = 0$} \\      
    \end{cases}
  \end{equation*}
  
  Example
  \begin{itemize}
  \item $D_{i} = 1$ if Alice goes to hospital; $D_{i} = 0$ otherwise
  \item $Y_{i}(1)$ is health status of Alice after going to the hospital
  \item $Y_{i}(0)$ is health status of Alice after \textbf{not} going to the hospital    
  \end{itemize}
  
\end{frame}


\begin{frame}
  \frametitle{The fundamental problem of causal inference}
  
  \begin{center}
    We never observe both $Y_{i}(1)$ and $Y_{i}(0)$
  \end{center}
  
\end{frame}



\subsection{Estimands}


\begin{frame}
  \frametitle{What causal effects are there?}
  
  Suppose poulation of units $i = 1, \dots, N$
  
  \begin{itemize}
  \item Individual Causal Effect (ICE): 
    \begin{equation*}
      \tau_{i} = Y_{i}(1) - Y_{i}(0)
    \end{equation*}
  \item Average Treatment Effect (ATE); averge causal effect
    \begin{equation*}
      \tau = \E(\tau_{i}) = \frac{1}{N} \sum_{i:X_{i} = x} Y_{i}(1) - Y_{i}(0)
    \end{equation*}
  \end{itemize}
  
\end{frame}


\begin{frame}
  \frametitle{Causal effects for subpopulations}
  
  Suppose poulation of units $i = 1, \dots, N$
  
  \begin{itemize}
  \item Individual Causal Effect (ICE): 
    \begin{equation*}
      \tau_{i} = Y_{i}(1) - Y_{i}(0)
    \end{equation*}
  \item Average Treatment Effect (ATE); averge causal effect
    \begin{equation*}
      \tau = \E(\tau_{i}) = \frac{1}{N} \sum_{i:X_{i} = x} Y_{i}(1) - Y_{i}(0)
    \end{equation*}
  \end{itemize}
  
\end{frame}


\begin{frame}

  \begin{itemize}
  \item Conditional Average Treatment effect (CATE) for a subpopulation
    \begin{equation*}
      \tau(x) = \E(\tau_{i} | X = x) = \frac{1}{N_{x}} \sum_{i: X_{i} = x} (Y_{i}(1) - Y_{i}(0))
    \end{equation*}
  \item Average treatement effect on the treated (ATT). Casual effect for those that were treated.
    \begin{equation*}
      \tau_{ATT} = \E(\tau_{i} | D_{i} = 1) = \frac{1}{\sum D_{i}} \sum_{i: D_{i} = 1} (Y_{i}(1) - Y_{i}(0))
    \end{equation*}
  \end{itemize}
  
\end{frame}


\begin{frame}
  \frametitle{Identification}
  \begin{itemize}
  \item If you had infinite data (entire population, no sampling variation) could you estimate the parameter uniquely?
  \item E.g. example of non-identification in regression is collinearity
  \item \textbf{Non parametric identification} Don't require a parametric model of data.
  \item \textbf{Parametric identification} Estimand identified assuming a parametric model of the data, 
    not identified otherwise
  \item Causal inference concerned with the identification of causal estimands like ATE, ATT.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{What's the key to causal inference?}

  \begin{center}
    Data + assumptions = causal inference
  \end{center}
  
  ``What's your identification strategy?'' means ``What assumptions are required to estimate a causal effect?''
  
\end{frame}


\begin{frame}
  \frametitle{How does the potential outcome relate to observed outcome?}
  
  \begin{itemize}
  \item Need a way to connect potential outcomes to observed outcomes.
  \item \textbf{SUTVA}: Stable unit treatment value assumption
  \item Also called a ``consistency'' assumption
  \item What is SUTVA?
    \begin{equation*}
      (Y_{i}(D) = Y_{i}) \to (T_{i} = D)
    \end{equation*}
  \item No interference between units. My potential outcome does not depend on other's treatment.
  \item Not all ``treatments'' can be used, there may ill-defined counterfactuals, multiple versions of the treatment, time
  \item If interference, need to redefine treatment or units
  \item Variation in treatment $D$ is irrelevant
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{The Fundamental Problem of Causal Inference}
  
\end{frame}


\begin{frame}
  \begin{itemize}
  \item Linear regression is causal when the CEF is causal
  \item Linear regression estimates the CEF, when the CEF is linear+ 
    \begin{itemize}
    \item $X$ is multivariate normal 
    \item $X$ is saturated, e.g.\@all combinations of binary $X$
    \end{itemize}
  \item $X'_{i} \beta$ is minimum MSE predictor of $Y_{i}$
  \item $X'_{i} \beta$ is minimum MSE predictor of the CEF, $E(Y_{i}|X_{i})$    
  \item Agnostic view of regression. Regression is a linear approximation of the CEF, 
    not necessarily the ``true model''. Heteroskedasticity is likely to occur when it is an 
    approximation.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Saturated Regression}
  
  Parameter for each unique combination of the covariates
  
  Regression fits CEF because the CEF is a linear combination of the categories
  
  \begin{equation*}
    Y_{i} = \alpha + \beta_{1} X_{1i} + \beta_{2} X_{2i} + \beta_{3} X_{1i} X_{2i} + \epsilon_{i}
  \end{equation*}
  
  \begin{align*}
    \E(Y_{i} | X_{1i} = 0, X_{2i} = 0) = \alpha
    \E(Y_{i} | X_{1i} = 0, X_{2i} = 1) = \alpha + \beta_{2}
    \E(Y_{i} | X_{1i} = 1, X_{2i} = 0) = \alpha + \beta_{1}
    \E(Y_{i} | X_{1i} = 1, X_{2i} = 1) = \alpha + \beta_{1} + \beta_{2} + \beta_{3}
  \end{align*}
  
  Linear regresion with the set of same set of covariates will fit the CEF because each value 
  of the CEF is estimated independently
  
  Most flexible linear regression model; Dropping interaction terms or making linearity assumptions on multi-category varaibles cause the regression model to be no longer saturated
  
  Saturated model perfectly fits the CEF, no assumptions about the CEF
  
\end{frame}


\begin{frame}
  \frametitle{Regression and Causality}
  
  Regression is causal when the CEF it approximates is causal (Angrist and Pischke 2008)
  
  Under certain conditions, the regression of the outcome on the treatment and covariates can recover a causal parameter (not always the one we are interested)
  
\end{frame}


\begin{frame}
  \frametitle{Average Treatment Effect, Average Treatment of the Treated}
  
  \begin{align*}
    \text{Individual Causal Effect} = \text{ICE} = Y_{i}(1) - Y_{i}(0) \\
    \text{Average Treatment Effect} = \text{ATE} = \E(Y_{i}(1) - Y_{i}(0)) \\
    \text{Average Treatment Effect, subpop} = \text{ATE} = \frac{1}{N_{f}} \sum_{i:X_{i} = f} (Y_{i}(1) - Y_{i}(0)) \\    
    \text{Average Treatment Effect on the treated} = \text{ATT} = \E(Y_{i}(1) - Y_{i}(0) | D_{i}  = 1)
  \end{align*}
  
  ATT. Matching methods chooise it. Fewer assumptions. Effect of a policy for those that actually use it.
  
\end{frame}


\begin{frame}
  \frametitle{Avg. Causal Effects and the Selection Bias}
    
  Observation and causal effects:
  \begin{align*}
    &\E(Y_{i}|D_{i} = 1) - \E(Y_{i} | D_{i} = 0)  && \text{Obs.\@difference in avg.\@health} \\
    &\quad = \E(Y_{1i}|D_{i} = 1) - \E(Y_{0i} | D_{i} = 1) && \text{Avg.\@treatment effect on treated} \\
    &\quad + \E(Y_{0i}|D_{i} = 1) - \E(Y_{0i} | D_{i} = 0) && \text{Selection bias}
  \end{align*}
  
  The \textbf{average causal effect on the treated}
  \begin{equation*}
    \E(Y_{1i} | D_{i} = 1) - \E(Y_{0i} | D_{i} = 1) = \E(Y_{1i} - Y_{0i} | D_{i} = 1)
  \end{equation*}
  
  E.g compare hospitalization
  Observed difference in averge health between hospitalized and non hospitalized is
  Average effect of hospitalization on health + the difference in health for those who went to the hospital and those that didn't if they didn't go to the hospital
    
\end{frame}


\begin{frame}
  \frametitle{Important Considerations when Using Regression for Casual Questions}
  
  \begin{itemize}
  \item Define a ``treatment variable'' and ``control variables''
  \item Consider only one ``treatment variable'':
    \begin{itemize}
    \item It is difficult to reasonably ensure selection on observables for different variables.
    \item Study the effects of one cause, not $H_{1}, \dots, H_{\infty}$
    \item Defining the causes of an effect is either hard or ill-defined
  \item Always ask yourself, what would be the ideal randomized experiment?
  \end{itemize}
  
\end{frame}


\begin{frame}
  \frametitle{Regression Analysis of Experiments}
  
  \begin{equation*}
    Y_{i} = \alpha + \rho D_{i} + \nu_{i} \\
    
  \end{equation*}
  
  
\end{frame}


\begin{frame}
  \frametitle{Bad Controls}
  
  $Y_{i}$ is income; $W_{i}$ is dummy for white collar; $C_{i}$ is dummy for college education
  
  \begin{align*}
    Y_{i} &= C_{i} Y_{1i} + (1 + C_{i})Y_{0i}\\
    W_{i} &= C_{i} W_{1i} + (1 + C_{i})W_{0i}
  \end{align*}
  
  $C_{i}$ randomly assigned, indep of potential outcomes
  
  \begin{align*}
    \E(Y_{i} | C_{i} = 1) - \E(Y_{i} | C_{i} = 0) &= \E(Y_{1i} - Y_{0i}) \\
    \E(W_{i} | C_{i} = 1) - \E(W_{i} | C_{i} = 0) &= \E(W_{1i} - W_{0i})
  \end{align*}
  
  \begin{equation*}
    \E(Y_{i} | W_{i} = 1, C_{i} = 1) - \E(Y_{i} | W_{i} = 1, C_{i} = 0) =
    \E(Y_{1i} | W_{1i} = 1, C_{i} = 1) - \E(Y_{0i} | W_{0i} = 1, C_{i} = 0)
  \end{equation*}
 
  \begin{equation*}
    \E(Y_{1i} | W_{1i} = 1, C_{i} = 1) - \E(Y_{0i} | W_{0i} = 1, C_{i} = 0) =
    \E(Y_{1i} | W_{1i} = 1) - \E(Y_{0i} | W_{0i} = 1)
  \end{equation*}

  Causal effect of college degree for those who work at a white collar job,
  selection bias, college changes the composition of white collar workers
  \begin{equation*}
    \E(Y_{1i} | W_{1i} = 1) - \E(Y_{0i} | W_{0i} = 1) =
    E(Y_{1i} - Y_{0i} | W_{1i} = 1) + \left(
      E(Y_{0i} | W_{1i} = 1) - E(Y_{0i} | W_{0i} = 1)
    \right)
  \end{equation*}
  
\end{frame}


\begin{frame}
  \frametitle{Heterogeneity and Non-linearity}
  
  Estimands ATT
  
\end{frame}


\begin{frame}
  \frametitle{Comments on ``Credibility Revolution''}
  
  \begin{itemize}
  \item Less concern about finding the \textbf{true model}
  \item More concern about removing OVB using design
  \item Focus on average effects
  \end{itemize}
\end{frame}



\section{References}


\begin{frame}
  \frametitle{References}

  \begin{itemize}
  \item Angrist and Pischke, \textit{Mostly Harmless Econometrics: An Empiricist's Companion}, Ch 2--3
  \item Angrist and Pischke, \textit{Mastering Metrics: The Path from Cause to Effect}, Ch 1--2
  \item Gelman and Hill, Chapter 9 and 10
  \item Matthew Blackwell, PSC 504 Notes, \url{http://www.mattblackwell.org/teaching/psc504/}.
  \item Matthew Blackwell, GOV 2002 Notes \url{http://www.mattblackwell.org/files/teaching/gov2002-syllabus.pdf}
  \item Gelman and Hill, Ch 5. This should have most material you need.
  \end{itemize}
\end{frame}


\end{document}
