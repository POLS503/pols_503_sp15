---
title: "POLS 503: Problem Set 4"
author: "Jeffrey B. Arnold, Christopher Adolph"
date: "April 30, 2015"
---

*Revised:* May 8, 2015

$$
\DeclareMathOperator{\cor}{cor}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\quantile}{quantile}
$$


```{r load,message = FALSE, echo = FALSE}
library("ggplot2")
library("dplyr")
library("broom")
library("tidyr")
```

TODO: go the typical route of data analysis. 

1. Analyze functional form of each variable with residuals
2. Compare models with out of sample testing.

# Instructions and Introduction

1. Create a new R project for this homework named `hw3` and load that project.
2. Do your analyses in an R markdown document based off of [hw3-template.Rmd](hw3-template.Rmd)
2. Download [hw3-functions.R](hw3-functions.R) and save in to your project directory.
3. Submit a zipped file of the directory with your R project through Canvas. This should contain all the materials for another person to run your R Markdown file  This should contain:

    - The R project (`.Rproj`) file
	  - The R Markdown document (`.Rmd`) of your analyses
	  - An HTML document (`.html`) compiled from your R Markdown document.
	  - Any data or other files needed to run the analyses in your R Markdown document.

4. Your R Markdown file should follow the guidance from [here](http://pols503.github.io/pols_503_sp15/r_markdown_assignments.html) and your R code should follow the guidelines [here](http://pols503.github.io/pols_503_sp15/r_best_practices.html).
5. Turn in a paper copy of the document compiled from the analyses at lab.
6. You can work together on this but you should each turn in your own assignments and write up your work separately.
   Include the names of your collaborators on your assignment.

# Problems {#problems}

## Showing Confidence

We revisit the sprinters data we considered in Problem Set 2

a. Add confidence intervals to the plots you made for Problem Set 2, problem 1d. using the predict() command to generate the confidence intervals around the expected finish times.

b. Rerun the analysis and recreate the plot, adding confidence intervals, for the
model:
    $$
    \log(\mathtt{Finish}_o) = \beta_9 + \beta_1 \mathtt{year}_i + \beta_2 \mathtt{women}_i + \beta_3 \mathtt{year}_i × \mathtt{women}_i + \epsilon_i
    $$
    Be sure to explain in words how this specification differs from the one used in
    part a.

c. Rerun the analysis and recreate the plot, adding confidence intervals, for the
model:
   $$
   \log(\mathtt{Finish}_o) = \beta_9 + \beta_1 \mathtt{year}_i + \beta_2 \mathtt{women}_i + \beta_3 \mathtt{year}_i × \mathtt{women}_i + \epsilon_i
   $$
   Be sure to explain in words how this specification differs from the ones used in part a. and b.
d. Compare the visual fit of these models to the data within the observed period.
    Which do you find plausible fits?
e. Do these models have different predictions for the Olympics of 2156? (Hint:
    extending your plots to go up to 2156 is an easy way to see this.) Why or why
    not?
f. Now create a new variable, the ratio of men’s time to women’s time in each
   year. Logit-transform this variable and regress it on year. Plot the results,    with
   confidence intervals, on the scale of the ratio men’s time to women’s time (i.e.,
   transform it back from logit). Does this approach make any assumptions about
   men’s times or women’s times that might be problematic?

## Model Selection: Oil & Democracy

For this problem, we will use a cleaned-up version of the dataset employed by Michael Ross in ``Does Oil Hinder Democracy?'' World Politics, 2001.
In that paper, we estimated a time series cross-section model of Polity scores regressed on oil exports and a battery of controls.
In this problem, we will focus on a single cross-section (saving the time series cross-section analysis for a later optional homework), and instead focus on model fitting and robustness to outliers.

A description of the included variables follows:

------------- -------------------------------------------------------------------------------------
`regime1`     1–10 scale increasing in democracy; computed from Polity components
`oilL5`       Fuel exports as a proportion of GDP, lagged 5 years
`metalL5`     Ore and mineral exports as a proportion of GDP, lagged 5 years
`GDPpcL5`     per capita GDP in PPP dollars, lagged 5 years
`islam`       Muslims as a proportion of population, 1970 data
`oecd`        Dummy for rich industrialized countries
`cty_name`    The name of the country observed
`id`          A three character abbreviation of the country name
`id1`         A numeric country code
`year`        The year of the observation (for this slice, it is always 1995)
------------- -------------------------------------------------------------------------------------

a. Load the dataset ross95.csv, which contains a partially cleaned cross-section of replication data for the year 1995.
    Estimate a linear regression of `regime1` on `oilL5`, ``metalL5`, `GDPpcL5`, `islam`, and `oecd`.
    Record the standard error of the regression, and calculate the expected change in `regime1` given a change in `oilL5` from the 50th percentile to the 95th percentile of the fully observed data, all else equal.
b. Using the residuals from the regression in part a., create the following diagnostic plots: (i) plot the residuals against the fitted values, (ii) plot the residuals against each covariate, (iii) plot the studentized residuals against the standardized hatvalues. What do these diagnostics tell you about the presence of heteroskedasticity, specification error, and outliers?
c. Rerun the regression using either log or logit transformations on any covariates you see fit. You will likely run several specifications. In each run, record the standard error of the regression, and the expected change in regime1 given a change in oilL5 from the 50th percentile to the 95th percentile of the fully observed data. See the appendix for some tips and warnings about transforming these data, though.
f. How much substantive difference does finding the best model make? (Be specific and concrete; i.e., show what each model does. I’m asking for a more detailed answer than you usually see in articles.) How much substantive doubt is there in the result if we are not sure which of the models you fit is the ``right'' one?
g. Which model of those you have estimated do you trust most, and why? What
other problems in the specification or estimation method remain unaddressed by
our efforts?

* * *

Derived from of Christopher Adolph, "Problem Set 4", *POLS/CSSS 503*, University of Washington, Spring 2014. <http://faculty.washington.edu/cadolph/503/503hw4.pdf>. Used with permission.

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
