---
title: "POLS 503 Lab 3"
author: "Carolina Johnson"
date: "Friday, April 17, 2015"
output: html_document
---
```{r echo=FALSE,results='hide'}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Outline

1. Check in: Questions from Homework, other lingering confusion
2. Review: Reading in data and initial data exploration
3. Linear regression
    a. Model specification in R
    b. `lm()` object and model results
    c. (Pre)Review model interpretation
4. An aside on R fundamentals: object types
5. Returning to regression:
    d. `predict()` 
    e. Plotting regression summary/expected values

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
```


## Reading in data review:

1. Download Iverson and Soskice data
    a. (alternatively, see if you can figure out how to read in a file directly from a webpage)
2. Generate summary statistics for all variables in the dataset (number of observations, min, max, median, mean, standard deviation)
3. Plot the distributions of each numeric variable

This dataset is cross sectional data on industrial democracies. Containing:

--------- --------------------------------------- 
`povred`  Percent of citizens lifted out of poverty by taxes and transfers  
`enp`     Natural log of effective number of parties  
`lnenp`   Natural log of effective number of parties  
`maj`     Majoritarian election system dummy  
`pr`      Proportional representation dummy  
`unam`    Unanimity government dummy (Switzerland)
--------- ----------------------------------------

Source of data & (and model for plot): Torben Iversen and David Soskice, 2002, “Why do some democracies redistribute more than others?” Harvard University.

```{r echo=FALSE, results='hide', fig.show='hide'}
iver <- read.csv("iver.csv", as.is=TRUE)
dim(iver)
iver
head(iver)
summarise_each(iver, funs(mean, sd))
mean <- summarise_each(iver, funs(mean))
sd <- summarise_each(iver, funs(sd))
min <- summarise_each(iver, funs(min))
max <- summarise_each(iver, funs(max))
median <- summarise_each(iver, funs(median))
rbind(mean, sd, min, max, median) %>% data.frame(row.names=c("mean", "sd", "min", "max", "median"))

povred.plot <- ggplot(iver, aes(povred)) + geom_histogram()
povred.plot
enp.plot <- ggplot(iver, aes(enp)) + geom_histogram()
enp.plot
lnenp.plot <- ggplot(iver, aes(lnenp)) + geom_histogram()
lnenp.plot
```

## Regression!
The basic command for linear regression in R is `lm()`. A call to this function takes the generic form illustrated below:
```{r eval=FALSE}
res <- lm(y ~ x1 + x2 + x3, data = your.dataframe)
```

To see a summary of the regression results use `summary()`:
```{r eval=FALSE}
summary(res)
```


Let's run a regression using the Iverson and Soskice data.  We save the regression as an object and then print the summary of the results:

**A simple bivariate model:**
```{r}
lm.bivar <- lm(povred ~ lnenp, data = iver)
summary(lm.bivar)
```

*Challenge:*

* How do we interpret this output? 
* What happens if you just type `lm.bivar`?

**A multivariate model:**
```{r}
lm.multi <- lm(povred ~ lnenp + maj + pr, data = iver)
summary(lm.multi)
```

### Aside on the formula 
Note: the first argument to the function is an R formula.  Formulas appear throughout many R functions, and have some special features of their syntax, some of which are illustrated below.  

In `lm`, the formula is used to generate the exact X matrix that will be used to estimate the model.  To see the matrix being generated internally by `lm`, add the argument `x = TRUE` to the `lm()` call:
```{r}
lm.multi <- lm.multi <- lm(povred ~ lnenp + maj + pr, data = iver, x = TRUE)
lm.multi$x
```

We'll look at this again in one of the more complicated model specifications below.

**A new model with multiple regressors and no constant:**
```{r}
lm.multi.noC <- lm(povred ~ -1 + lnenp + maj + pr + unam, data = iver)
summary(lm.multi.noC)
```

**A new model with multiple regressors and an interaction:**
```{r}
lm.multi.interact <- lm(povred ~ lnenp*maj + pr, data = iver)
summary(lm.multi.interact)
```

If you want to add an interaction separately from the individual variables being interacted:
```{r}
lm.multi.interact <- lm(povred ~ lnenp + maj + pr + lnenp:maj, data = iver)
summary(lm.multi.interact)
```

### Second aside on formulas
To better understand what the formula is doing, let's look at the model matrix one of the more complex formulas above generates:
```{r}
lm.multi.interact <- lm(povred ~ lnenp*maj + pr, data = iver, x = TRUE)
lm.multi.interact$x
```

**A new model with multiple regressors and a transformation:**
(This transformation is just illustrating that you have the option of taking the log of a variable *inside* the formula, rather than creating a new variable prior to fitting).
```{r}
lm.multi.log <- lm(povred ~ log(enp) + maj + pr, data = iver)
summary(lm.multi.log)
```

You can also do other transformations such as taking the square of a variable (we'll talk more abou this substantively later in the course):
To apply a mathematical function to a variable within the formula object, enclose it in `I()`.
```{r}
lm.multi.sq <- lm(povred ~ enp + I(enp^2) + maj + pr, data = iver)
summary(lm.multi.sq)
```

But what is this `lm()` object? Is it a dataframe?
```{r}
is.data.frame(lm.multi)
```
No!  

## An aside on R fundamentals: Object types

R has many different types of objects, that store information in different ways and are treated differently by different functions.

Some of the most common types of objects are:

1. Vectors
2. Matrices
3. Dataframes
4. Lists

(Much of this should be review if you completed the R Data Camp)

### Vectors 

Vectors are collections of single values, with a length equal to the number of items in the set. 

For example, here is a vector of names:
```{r}
names <- c("Sarah", "Melina", "Jefferson", "Brad", "Ashley")
print(names)
```

And here is a vector of numbers:
```{r}
numbers <- c(1,2,3,4,5,6,7,8,9,10)
print(numbers)
```
Another way to creat the same vector could have been:
```{r}
number_sequence <- seq(from = 1, to = 10, by = 1)
```

You can extract an item from a vector using square brackets:
```{r}
numbers[5]
names[2:3]
```

Single variables in our dataframe are *also* vectors. This is how we can do operations on them such as calculating the mean.

```{r}
countries <- iver$cty
countries
countries[3:5]
iver$cty[3:5]
```


### Matrices
Matrices are collections of equal-length vectors in row and column arrangement.  Matrices store information in a rectangular format, so look like dataframes, but are less flexible as all data must be the same type (you can't mix character and numeric data, for example).  At first when you start working in R, matrices will be in use behind the scenes more than something you work with much.  

As an example, see what happens when we convert our dataframe into a matrix:
```{r}
iver.matrix <- as.matrix(iver)
iver.matrix
```
Why is everything in quotation marks now?

You can index a matrix using square brackets, indicating first the row you want, then the column. This is the same way that you could directly extract specific values from a dataframe

```{r}
iver.matrix[2:4,] # a blank before or after the comma indicates all rows or columns, respectively
iver.matrix[8,4]
```


### Dataframes
You've  seen these a lot! Now there are all kinds of tools to exploit the features of dataframes, many of which you're familiar with.  

For the sake of completeness, here's the equivalent "base R" way of pulling out (or indexing) a dataframe to select rows or colums that meet certain criteria (you will likely see this in other's code or in help files etc as you explore resources on your ow):

First, let's select all countries with a majoritarian system of government:
```{r}
iver[iver$maj==1, ] # this selects all columns
```

Next let's subset the data to all majoritarian countries but only keep the columns povred and lnenp (for example)
```{r}
iver[iver$maj==1, c("povred", "lnenp")]

#let's keep the country names too!
iver[iver$maj==1, c("cty", "povred", "lnenp")]
```

Here's how you create a new dataframe from scratch:
```{r eval=FALSE}
mydata <- data.frame(variable1 = a.vector,
										 variable2 = another.vector,
										 variable3 = yet another vector)
```

An example:
```{r}
mydata <- data.frame(somenumbers = seq(1,50,7),
										 somewords = c("pounce", "bounce", "IPA", "crescent"),
										 is.silly = c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE))
mydata
```

Note, vectors must be either the same length or even multiples of each other's length (shorter vectors will be repeated)

mydata <- data.frame(somenumber = seq(1,50,3),
)

### Lists
Finally, another object type is the list, which can store different types of R objects (kind like a vector, but instead of values of a variable, they're objects we might want to save and come back to).  Lists are everywhere. Many of the functions we use (such as `lm()`) return lists.  Dataframes are even a special kind of list!

List elements have names. The easiest way to access an element of a list is to use the `$` and the name (just like looking at a variable in a dataframe).

To find out what in a list us `str()` and/or `names()`

*Challenge:* 

1. Use `names()` and `str()` to explore the contents of one of the lm objects you've created. (Look at the help file for `lm` for further details)
2. Extract and save as separate objects:
    a. The coefficients
    b. The residuals (what are the residuals?)
    c. The fitted values (what are the fitted values?)

```{r}
# A:
coefficients.multi <- lm.multi$coefficients
coefficients.multi
# or
coef(lm.multi) #This is making use of the "attributes" of the lm object, a programming detail we're not going to talk about today

# B
residuals.multi <- lm.multi$residuals
residuals.multi
#or
resid(lm.multi)

# C
fitted.multi <- lm.multi$fitted.values
fitted.multi
#or
fitted(lm.multi)
```

*Challenge:*

1. What important information is missing from the `lm()` list?

To extract standard errors of the estimates:
```{r}
se.multi <- lm.multi %>% vcov() %>% diag %>% sqrt
```
This calculates the standard errors by calculating the square root of the diagonal of the variance-covariance matrix of the parameters of the model object.  `vcov()` is an example of a function that has a specific "method" for different types of objects: it knows we have an  `lm` object and acts accordingly.

## Returning to regression

### Fitted values and predictions for new or hypothetical data
Another way to get the fitted values is with `predict()`:
```{r}
predict(lm.multi)
```

The nice thing about predict is that it will actually let us calculate the expected values from our model for any set of real or hypothetical data with the same X variables:

Here's the general form of a call to predict, giving 95% confidence intervals:
```{r eval=FALSE}
predict(object, #lm object
        newdata, # a dataframe with same x vars as data, but new values
        interval = "confidence",
        level = 0.95 #the default
)
```

Let's try this with our model.  

*Challenge:* 

1. What would we expect the level of poverty reduction to be for a majoritarian country with 2 parties?
2. What would we expect the level of poverty reduction to be for a PR country as it goes from 1 to 5 parties?

*hint (refer to dataframe info above for how to create a new dataframe for newdata argument)
```{r}
#1:
predict(lm.multi, newdata = data.frame(lnenp = log(2), maj = 1, pr = 0), interval = "confidence")
predict(lm.multi, newdata = data.frame(lnenp = log(seq(1:5)), maj = 1, pr = 0), interval = "confidence")
#or
xnew <-  data.frame(lnenp = log(seq(1:5)), maj = 1, pr = 0)
predict(lm.multi, newdata = xnew, interval="confidence")
#or
data.frame(lnenp = log(seq(1:5)), maj = 1, pr = 0) %>% predict(lm.multi, newdata=., interval="confidence")
```

### Plotting regression results
Plotting regression results can be even more informative. Informationally dense, and more intuitive than regression tables!

To plot a regression line (not just using the `lm` smoother in ggplot), you can either fit a line to the observed values of X and the fitted values and CIs from `predict`, or fit a line to hypothetical data to illustrate the estimated relationship (the latter can help you to have smoother confidence intervals where you have fewer observations).

Generate a range of hypothetical values for a key variable of interest:
```{r}
lnenp.hyp <- seq(min(iver$lnenp), max(iver$lnenp), 0.1)
```

Calculate expected values of `povred` for each observed level of `lnenp`, setting the covariates to an fixed level, often to the mean (illustrating the effect of a change in `lnenp`, all else equal).  Remember to keep variable names identical to those in the model!
```{r}
yhyp <- data.frame(lnenp = iver$lnenp, maj = mean(iver$maj), pr = mean(iver$pr)) %>%
	predict(lm.multi, newdata = . , interval = "confidence")
```

We'll use these values of X and y to plot the regression line over a scatterplot of the observed data using ggplot2:
```{r}
plot <- ggplot(iver, aes(x = lnenp, y = povred, label = cty))

plot <- plot + geom_ribbon(aes(ymin = yhyp[,2], ymax = yhyp[,3]), alpha = (1/3)) + geom_line(aes(x = lnenp, y = yhyp[,1])) # adds line and CI
plot

plot + geom_text(data = filter(iver, maj == 1), color = "red", size = 3) +
	geom_text(data = filter(iver, pr == 1), color = "blue", size = 3) +
	geom_text(data = filter(iver, unam == 1), color = "green", size = 3) +
	theme_minimal()
```

**CHECK**
!!!!! ???? There has to be a better way to easily color by party system and include a legend - appreciate that this is b/c it's a set of dummies rather than a single factor variable, but surely there's a better solution?
